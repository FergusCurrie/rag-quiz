{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating prompts \n",
    "\n",
    "Prompts are stored in database, so that llm generated data can be tied to prompts, for future eval of prompt. \n",
    "\n",
    "This notebook gives a simple mechanism to update the prompts (these will not be updated regualrly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<backend.models.PromptStore at 0x7bfdd8f008f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from backend.connections import get_postgres_db\n",
    "from backend.crud import create_prompt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# PROMPT_QUESTION = \"\"\"\n",
    "# You will be provided information on a concept from an academic STEM subject. \n",
    "# You will use your knowledge to generate 5 questions and answers to test the students knowledge of the concept. \n",
    "# The questions should be no more than a few sentences. \n",
    "# Give your answer in the format: \n",
    "# 1. \n",
    "# Question: <question>\n",
    "# Answer: <answer>\n",
    "# 2.\n",
    "# ...\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# create_prompt(\n",
    "#     next(get_postgres_db()),\n",
    "#     prompt_type='generate_qa',\n",
    "#     prompt=PROMPT_QUESTION\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PROMPT_ANSWER = \"\"\"\n",
    "# You are judging the answer of a student to a quiz question. \n",
    "# You will be provided the following:\n",
    "# Question: \n",
    "# Answer: \n",
    "# Correct Answer: \n",
    "# Using a combination of your own knowledge and the correct answer, please give a short judgement on the quality of the answer and provide a rating between 1 and 10. \n",
    "# Where 10 is perfect and 1 is terrible answer. \n",
    "# Please respond with:\n",
    "# Response: \n",
    "# Score: \n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# create_prompt(\n",
    "#     next(get_postgres_db()),\n",
    "#     prompt_type='judge_answer',\n",
    "#     prompt=PROMPT_ANSWER\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_id': UUID('25d1a107-44ae-45dc-a79a-2de72c47eff7'), 'prompt_type': 'generate_qa', 'prompt': '\\nYou will be provided information on a concept from an academic STEM subject. \\nYou will use your knowledge to generate 5 questions and answers to test the students knowledge of the concept. \\nThe questions should be no more than a few sentences. \\nGive your answer in the format: \\n1. \\nQuestion: <question>\\nAnswer: <answer>\\n2.\\n...\\n', 'created_date': datetime.datetime(2025, 1, 17, 3, 20, 34, 534403)}\n",
      "{'prompt_id': UUID('9c7bd37c-fa33-40bd-b012-129472117bfe'), 'prompt_type': 'judge_answer', 'prompt': '\\nYou are judging the answer of a student to a quiz question. \\nYou will be provided the following:\\nQuestion: \\nAnswer: \\nCorrect Answer: \\nUsing a combination of your own knowledge and the correct answer, please give a short judgement on the quality of the answer and provide a rating between 1 and 10. \\nWhere 10 is perfect and 1 is terrible answer. \\nPlease respond with:\\nResponse: \\nScore: \\n', 'created_date': datetime.datetime(2025, 1, 17, 3, 21, 3, 800193)}\n"
     ]
    }
   ],
   "source": [
    "from backend import models \n",
    "\n",
    "prompts = next(get_postgres_db()).query(models.PromptStore).all()\n",
    "for p in prompts:\n",
    "    print(p.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-quiz-_842fax4-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
